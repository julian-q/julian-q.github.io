<p style="margin-top: 0px;">At the start of this year, I realized I wanted to leave school and go work on <i>world models</i> full-time.</p>

<p>What's a world model? Another word for it would be <i>world simulator</i>. A simulator's job is to predict the next state of a system given the previous state(s). Usually, when we talk about simulators, we're talking about physics simulators, which predict the next state of some physical system. They sort of do this by (1) taking in all the information about the current system, like the positions and velocities of all the particles within the system, (2) using this information to compute new forces on particles, and then (3) updating the positions and velocities by applying those forces across a small time step. If you do this enough times, and take a whole bunch of those small time steps, you'll get a prediction of how that physical system evolves over time.</p>

<p>The world is full of amazingly complex physical systems, each with its own set of relevant physical laws, materials, and time scales. That's why physics simulators are usually individually designed for bespoke physical systems: <a href="https://flipfluids.com">fluid simulators</a>, <a href="https://www.cs.cmu.edu/~baraff/papers/sig98.pdf">cloth simulators</a>, <a href="http://www.hair-farm.com/about.php">hair simulators</a>, <a href="https://pybullet.org/wordpress/">rigid body simulators</a>, or <a href="https://www.gromacs.org">molecular dynamics simulators</a>. <i>World simulators</i>, on the other hand, aim to simulate the entire world. Their goal is to predict the next state of <i>the world</i>, with all of its complex physical interactions, all within a single computational model.</p>

<p>Take a moment to notice what's in your field of view. You might be sitting in a chair, in front of a computer resting on a table. Or you might be reading this on a device in your hand while you sit somewhere nice. Wherever you are, take a mental snapshot of your field of view. In a way, this can be seen as the <i>state</i> of the world. A world model takes the current state of the world as input - in this case your field of view at time <i>t</i> - and predicts the next state of the world - your field of view at time <i>t</i>+1.</p>

<p>Your field of view evolves constantly. You turn your head to look around, focus your eyes on different things, actuate your hands to touch and hold things, to type and click around, and use your legs to move around your environment. And even when you remain perfectly still, the world evolves around you. Raindrops splash on the ground, and grass and trees rustle in the wind. Animals move around. People talk to one another.</p>

<p>Today's world models will sort of look like this - predicting the next frame in a video taken from a first-person perspective. While this is not quite the same as predicting the next state of the entire world yet (what about things which I cannot see? tiny, atomic interactions? the interactions of people outside my direct vicinity? larger things, like the movement of our planet around the sun?), it is already an incredible objective - and an enormously challenging one.</p>

<p>We have already gotten into two major requirements of world models. First, we need them to be <i>interactive</i>. In order to simulate our world, we need to be able to tell the model what actions we intend to take, whether that be as simple as our intended movement direction and view orientation, or as complex as the contractions of every muscle in our body. This allows world models to be more useful by enabling us to ask "what if?" questions: what if I walked over here? what if I looked around this corner? what if I pushed this glass of water off of the table? (last question was submitted by a cat. submit your questions <a href="mailto:julianq@stanford.edu">here</a>.) Just as physics simulators are more useful when we get to script certain object movements, <a href="https://mujoco.org">control robots with policies</a>, or <a href="https://www.newgrounds.com/portal/view/218014">drag objects around with a mouse</a>, world simulators are much more useful when they are action-controllable.</p>

<p>Second, world simulators must accurately evolve the world around us, regardless of the input we provide. If we push a glass of water off the table, the water should spill and the glass should probably break. If we command our simulated self to pull on a door that says push, then we should be just as embarrassed. More generally, the world is full of rich interactions which we are often just observers of. If your initial field of view is you sitting in a coffee shop, then a good world model must predict accurate rollouts of future frames, which necessarily includes the body language, mouth movements, and audio of humans drinking coffee and having great conversations.</p>

<p>We're starting to see how world models, formulated as solving the next-frame prediction objective, face huge challenges. When the world is full of complex physical interactions, and the behaviors of creative, intelligent beings, predicting a pixel-perfect next frame requires getting <i>a ton</i> of things right.</p>

<p>The next-frame prediction objective is truly amazing. Imagine passing such a model a first-person image of you typing on your laptop. To predict the next frame accurately, the model must capture the relationship between keypresses and characters appearing on the screen, as well as how your finger's movement on the trackpad maps to cursor movement on the screen. And when it appears as if you have clicked something, a good world model should predict a realistic next state of the application you are currently using. A great world model is tasked with simulating complete computer functionality, potentially including the correct terminal output of a program typed out on the screen. This also could include creating brand-new applications from limited information. For example, if you click on something that looks like a game icon, a playable game should probably appear, and if you enter a URL of a website that might plausibly exist, the screen should fill with plausible HTML (see <a href="https://websim.ai">websim</a>).</p>

<p>While some of these examples probably seem far-fetched, I'm excited because I think they might actually be possible. I feel optimistic because world modeling with the next-frame prediction objective really plays to the strengths of modern AI. Next-frame prediction is just one example of the broader sequence modeling problem, which has seen wild success in language. Given a vast amount of example token sequences to learn from, language models have gotten remarkably good at predicting the next-plausible thing in a sentence. So, I feel that, with vast amounts of frame sequences to learn from, world models will get amazingly good at predicting the next-plausible frame in a video.</p>

<p>Video data is vast. There is at least 500,000 years worth of video on YouTube. To compare with text data, let's assume there are an average of 30 spoken words per minute across all YouTube videos. That means there are well over 10 trillion language tokens <i>alone</i> in all of YouTube. And of course, the real value of YouTube data is that it is a vast store of world dynamics data.</p>
<!-- To be continued. Computer screens, software, humans, brains, physics, etc. -->
